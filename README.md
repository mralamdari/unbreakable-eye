# ðŸ‘ï¸ Unbreakable Eye
> **Production-Grade Edge AI Inference Microservice**

[![CI Pipeline](https://github.com/mralamdari/unbreakable-eye/actions/workflows/ci.yml/badge.svg)](https://github.com/mralamdari/unbreakable-eye/actions)
![Python](https://img.shields.io/badge/python-3.10-blue)
![Docker](https://img.shields.io/badge/docker-containerized-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green)

**Unbreakable Eye** is a hardware-agnostic computer vision pipeline designed for scalability and reliability. It decouples the model logic from the application layer, allowing hot-swapping of inference engines (YOLOv8, YOLOX, RT-DETR, OpenVINO) without code changes.

---

## âš¡ Key Features

*   **ðŸ­ Universal Factory Pattern:** Plug-and-play support for Ultralytics, ONNX Runtime, and OpenVINO backends.
*   **ðŸ³ Docker Native:** Multi-stage build (under 500MB) optimized for Edge deployment (Jetson/RPi) and Cloud (AWS/GCP).
*   **ðŸ›¡ï¸ Robust Config:** Strictly typed configuration using Pydantic Settings (The 12-Factor App methodology).
*   **ðŸ“¡ Async Streaming:** Low-latency MJPEG streaming and JSON metadata endpoints via FastAPI.
*   **ðŸ“Š Observability:** Structured JSON logging (Loguru) ready for Datadog/ELK stacks.

---

## ðŸ—ï¸ Architecture

```mermaid
graph TD
    A[Camera / RTSP] -->|Stream| B(VisionPipeline)
    subgraph Core Engine
    B -->|Frame| C{Model Factory}
    C -->|Load| D[Model: YOLO/RT-DETR]
    D -->|Detections| E[Tracker: ByteTrack]
    end
    E -->|Annotated Frame| F[FastAPI Server]
    F -->|MJPEG Stream| G[Web Client / Dashboard]
    F -->|JSON Data| H[Cloud Database]
```

---

## ðŸš€ Quick Start

### Option A: Docker (Recommended)
The system is ready to run in any container runtime.

```bash
# 1. Build the image
docker build -f infra/docker/Dockerfile -t unbreakable-eye .

# 2. Run the container (with GPU support if available)
docker run -it -p 8000:8000 --env-file .env unbreakable-eye
```

### Option B: Local Development
```bash
# 1. Install Dependencies (Poetry)
pip install -e .

# 2. Configure Environment
cp .env.example .env
# Edit .env to set your RTSP_URL and MODEL_TYPE

# 3. Start Server
python -m src.server.main
```

---

## ðŸ”§ Configuration
Control the pipeline via Environment Variables (`.env`). No code changes required.

| Variable | Default | Description |
| :--- | :--- | :--- |
| `RTSP_URL` | `0` | Camera URL (rtsp://...) or Webcam ID |
| `MODEL_ARCH` | `yolov8` | Engine to use: `yolov8`, `yolox`, `rtdetr`, `openvino` |
| `DEVICE` | `cpu` | Hardware accelerator: `cpu`, `cuda`, `gpu` |
| `LOG_JSON` | `False` | Set `True` for production JSON logs |

---

## ðŸ“‚ Project Structure
```text
unbreakable-eye/
â”œâ”€â”€ infra/              # DevOps (Docker, K8s, Terraform)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/           # Config & Logging (The Brain)
â”‚   â”œâ”€â”€ engine/         # Pipeline & Tracker (The Heart)
â”‚   â”œâ”€â”€ vision/         # Model Factory & Handlers (The Eyes)
â”‚   â””â”€â”€ server/         # API & Routers (The Mouth)
â””â”€â”€ pyproject.toml      # Dependency Management
```

---

## ðŸ“œ License
MIT License.
```
